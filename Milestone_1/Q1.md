## Prompt
The following is a conversation between a client and a compression ai model who compresses the text by tokenizing the string into words and spaces and special characters indexing each token by it's index of it's first appearence [0 based]. So in the compressed paragraph every token appearing again will be replaced by the index of it's first appearence enclosed by '[',']' if the length of the token is lesser than greater than 3.

Client : Compress the following paragraph enclosed by delimiters as 3 backtics
```
my name is anirudh. my friend's name is gojo. my favourite anime is jujutsu kaisen. this is a test paragraph.
```
AI tool : Here is your compressed paragraph
```
my name is anirudh.my friend's [2] is gojo. my favourite anime is jujutsu kaisen.this is a test paragraph.
```

Client: Now reconstruct the original paragraph.

AI tool : Now replacing the index with it's token, the original paragraph is the following:
```
my name is anirudh. my friend's name is gojo. my favourite anime is jujutsu kaisen. this is a test paragraph.
```

Client: Compress the following paragraph enclosed with backtics

```
Never give in. Never give in. Never, never, never, never-in nothing, great or small, large or petty-never give in, except to convictions of honor and good sense. never trust anyone.
```

## Completion

AI tool: Here is your compressed paragraph:

```
Never give in. [1] , never, [1] -in nothing, great or small, large or petty- [1] , except to convictions of honor and good sense. never trust anyone.
```

Client: Now reconstruct the original paragraph.

AI tool: Now replacing the index with its token, the original paragraph is the following:

```
Never give in. Never give in, never, never, never, never-in nothing, great or small, large or petty-never give in, except to convictions of honor and good sense. Never trust anyone.
```

Please note that the compression algorithm you provided replaces repeated tokens with the index of their first appearance enclosed in brackets. However, the algorithm seems to have an inconsistency for tokens with a length greater than 3, as they are not compressed in the provided example.

## Remarks

ChatGPT wasn't able to perform well in the role-play prompt and wasn't able to follow through the algorithm well.
